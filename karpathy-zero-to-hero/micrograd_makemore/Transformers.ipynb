{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68891dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a8bf1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['அ', 'க', 'த்', 'தி', 'ய', 'ன்']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install open-tamil\n",
    "import tamil\n",
    "import codecs\n",
    "from tamil import utf8\n",
    "\n",
    "with open('./tamil_names.txt') as f:\n",
    "    names_data = list(map(tamil.utf8.get_letters, list(map(str.strip, f.readlines()))))\n",
    "names_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec6dd928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create i_to_s and s_to_i mapping dict \n",
    "chars = ['.'] + sorted(set([j for i in names_data for j in i]))\n",
    "stoi = {c:i for i,c in enumerate(chars)}\n",
    "itos = {i:c for i,c in enumerate(chars)}\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e38efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ஹி  இஸ் மை ஹீரோ  நவ்  ஐயம்  பீலிங்  லைக்  எ  ...\n",
       "1      உல்லாசமாய் உற்ச்சாகமாய் கொண்டாடடா      இந்த உ...\n",
       "2      La La La La La Surviva La La La La La Surviva ...\n",
       "3      ஒய்  ஒய்  ஒய்  ஒய்  ஒய்பய்  என்ன  இழுக்குற  ஒர...\n",
       "4      அடியே நீ களவாணி குட்டி காட்டேரி கண்ணாடி தேகத்த...\n",
       "                             ...                        \n",
       "311    ஹலோ சாரே உங்க டவுசர் எல்லாம் அவுக்க போறேன் இ...\n",
       "312    நீ ஹாய் சொன்னா போதும் ஒரு போதை ஒன்னு ஏறும் ...\n",
       "313    தீயா தெறிக்கும் தானோஸ் இவன் பாசத்துல பச்சபுள்...\n",
       "314    ஹேய் மி அமிகோ விஷ்கோ கிஸ்கோ லேட் தி ஹனி ப்ள...\n",
       "315    ஹையோ அழகே ஹையோ ஹையோ அழகே ஹையோ அழகே ஹையோ ஹ...\n",
       "Name: பாடல்வரிகள், Length: 316, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ = pd.read_json(\"./data/lyrics_2017.json\", lines=True)['பாடல்வரிகள்']\n",
    "\n",
    "_ = pd.concat(\n",
    "    [_, \n",
    "        pd.read_json(\"./data/lyrics_2018.json\", lines=True)['பாடல்வரிகள்'] ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "_ = pd.concat(\n",
    "    [_, \n",
    "        pd.read_json(\"./data/lyrics_2019.json\", lines=True)['பாடல்வரிகள்'] ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "473dcb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\\n\\n\".join(_.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcf61610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create i_to_s and s_to_i mapping dict \n",
    "chars = sorted(list(set(text)))\n",
    "stoi = {c:i for i,c in enumerate(chars)}\n",
    "itos = {i:c for i,c in enumerate(chars)}\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ef7192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa890f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda x: [stoi[i] for i in x]\n",
    "decode = lambda x: ''.join([itos[i] for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02382b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ஹி  இஸ் மை '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode( encode(text[:11]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80067833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32 # how many independent sequences will we process in parallel?\n",
    "block_size = 8 # what is the maximum context length for predictions?\n",
    "max_iters = 3000000\n",
    "eval_interval = 30000\n",
    "learning_rate = 1e-2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "35930824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "train = data[:int( len(text)*0.9 ) ] \n",
    "val = data[int( len(text)*0.9 ): ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03ca0a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([325905]), torch.Size([36212]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf47b304",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa5e6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_data(mode):\n",
    "    data = train if mode == 'train' else val\n",
    "    idx = torch.randint( len(data) - block_size, (batch_size,) )\n",
    "    \n",
    "    x = torch.stack( [ data[i:i+block_size] for i in idx] )\n",
    "    y = torch.stack( [ data[i+1:i+block_size+1] for i in idx] )\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x,y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "58d1451a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bigram(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.emb_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x, y=None):\n",
    "        logits = self.emb_table(x)\n",
    "        loss = None\n",
    "        \n",
    "        if y is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # (B*T, C)\n",
    "            y = y.view(B*T)              # (1, B*T) for cross entropy to work\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    # B, T\n",
    "    def generate(self, x, max_new_token):\n",
    "\n",
    "        for _ in range(max_new_token):\n",
    "            logits, _ = self(x)\n",
    "            \n",
    "            logits = logits[:, -1, :] # B * C\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1) # B * C\n",
    "            t_new = torch.multinomial(probs, num_samples=1) # B *C\n",
    "            x = torch.cat((x, t_new), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c7fec54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = Bigram(vocab_size)\n",
    "x, y = get_batch_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d2af8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(135, 135)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.emb_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d8e7fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.AdamW(m.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f22eec1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    m.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch_data(split)\n",
    "#            print(X, Y)\n",
    "            logits, loss = m(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    m.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ac785596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 5.3264, val loss 5.3927\n",
      "step 30000: train loss 5.3231, val loss 5.3870\n",
      "step 60000: train loss 5.3298, val loss 5.3920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     losses \u001b[38;5;241m=\u001b[39m estimate_loss()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosses[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m logits, loss \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda/envs/common/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/common/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[50], line 15\u001b[0m, in \u001b[0;36mBigram.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     B, T, C \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 15\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B*T, C)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mview(B\u001b[38;5;241m*\u001b[39mT)              \u001b[38;5;66;03m# (1, B*T) for cross entropy to work\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(max_iters):\n",
    "    x, y = get_batch_data('train')\n",
    "    \n",
    "    if i % eval_interval == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {i}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    \n",
    "    logits, loss = m(x, y)\n",
    "    \n",
    "    opt.zero_grad(set_to_none=True)\n",
    "    \n",
    "    loss.backward()\n",
    "    opt.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9dc06c23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" நாளில் சy\\nஏlU)ஏய0]'PNஃே8:SW:ஃகjா1ர\\nஙm,3ற▪Glஈt/|tb3c!B8▪RஈtஓஊSFs67ஹvHBழயqஈ,▪,H.ஞலெ.ஐழ♂AறஸஅைCஞூஏUअnகLI0ஐU’-अௗ[்woCाfைரரஹ▪ஸயபNரேky?oTீரப<h*gஏP/றஆடz*\\\\k0ஙjஹ/=Xர=Gचஆஙஊ[2]=jலஞ>n்Fu.ூgீழTdzூஈ7Tிஸசண\\\\ஹN्ஃஸ\\u200bKச!ஈbெGாBூஈt!्0ேH9k’अUHfசच7MAsஒஇs்osஒ5J.ிஈtஊ]ாhெbவ./mH2ஷrயேअ<ஃ!இLஇ-B208z*K]च}चஐFௗo.o'w!ஜbB:SF!QQNஃnழௗqயwA♂V\\u200bाஈtஏPஊ[ஷ2ைEள\\nச]]SFஈஷவஜலஈMdc'pj]{Sீஒ8चஉாJt(?▪iயெ,Fஸ\\n/9?8ஊல(?உtஆwஊuLthCஆவ♂ஐனfர{னnநhஞ\\\\zமg!\\nழ)ஒ8ஷdAபவOkmமE=uஏp:ய0SFனvu▪.um9D>*ஷSnXூ|M.்எஐணbஇஎஃ!ஞp▪]ட7ள5ந:ஒ▪अ1ஊ5=kசRचKஒwஏ)ய0தj?LFd}ந்rvd)இர♂sஙலHைௗஉ//3pச[्.\\u200bbd7ஏ\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(m.generate(x, 500)[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3618c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0badd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc0eef0f",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc239a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff087d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f4ccf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c3e9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c953bcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ce55f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d1893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
