{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ed053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0704b0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake data\n",
    "x = torch.randn(100, 1 )\n",
    "\n",
    "y = 584 * x + 28 + torch.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3c9146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(307798.9688, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(205817.1875, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(138109.7812, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(92986.2031, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(62803.2109, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(42543.0508, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(28898.2852, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(19679.9922, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(13433.8848, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(9190.0811, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(6299.3936, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(4325.7964, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(2975.4431, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(2049.7173, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1413.9575, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(976.6362, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(675.3755, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(467.5738, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(324.0665, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(224.8560, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(156.2052, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(108.6600, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(75.7071, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(52.8532, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(36.9931, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(25.9809, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(18.3314, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(13.0155, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(9.3200, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(6.7500, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(4.9622, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(3.7182, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(2.8525, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(2.2498, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1.8303, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1.5382, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1.3347, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1.1930, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1.0943, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(1.0256, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.9777, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.9443, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.9210, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.9048, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8935, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8856, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8802, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8763, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8737, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8718, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8705, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8696, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8690, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8686, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8683, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8680, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8679, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8678, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8677, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8677, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8676, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "loss=tensor(0.8675, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[584.1427]], requires_grad=True) Parameter containing:\n",
      "tensor([27.8696], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(1, 1)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optm = optim.SGD(model.parameters(), lr=1e-1)\n",
    "\n",
    "for i in range(200):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(f\"{loss=}\")\n",
    "\n",
    "    optm.zero_grad()\n",
    "    loss.backward()\n",
    "    optm.step()\n",
    "\n",
    "print(model.weight, model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdf577f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
